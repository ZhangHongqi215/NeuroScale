{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d5731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf104cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFastaData(fasta_path):\n",
    "    fasta_file = fasta_path\n",
    "\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append({\n",
    "            \"id\": record.id,\n",
    "            \"sequence\": str(record.seq)\n",
    "        })\n",
    "\n",
    "    result = []\n",
    "    for sequence in sequences:\n",
    "\n",
    "        result.append(sequence[\"sequence\"])\n",
    "\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf9136cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = getFastaData(r'')\n",
    "n = getFastaData(r'')\n",
    "p_label = [1 for i in range(len(p))]\n",
    "n_label = [0 for i in range(len(n))]\n",
    "feature = p + n\n",
    "label = p_label + n_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aafcf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, AutoTokenizer,BertModel, AutoModel \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "class myModel(torch.nn.Module):\n",
    "    def __init__(self,esm2):\n",
    "        super(myModel,self).__init__()\n",
    "        self.esm2 = esm2\n",
    "        self.fc1 = torch.nn.Linear(640,64)\n",
    "        self.fc2 = torch.nn.Linear(64,1)\n",
    "        \n",
    "        self.fc31 = torch.nn.Linear(640,128)\n",
    "        self.fc32 = torch.nn.Linear(128,64)\n",
    "        \n",
    "        self.fc41 = torch.nn.Linear(640,32)\n",
    "        self.fc42 = torch.nn.Linear(32,64)\n",
    "        \n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = torch.nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.4)\n",
    "    def forward(self,x):\n",
    "        outputs_ = self.esm2(**x)\n",
    "\n",
    "        x = outputs_.last_hidden_state[:, 0, :]\n",
    "        x = self.dropout1(x)\n",
    "        x1 = self.fc1(x)\n",
    "        x1 = self.relu(x1)\n",
    "        x1 = self.dropout2(x1)\n",
    "        \n",
    "        x2 = self.fc31(x)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = self.fc32(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = self.dropout2(x2)\n",
    "        \n",
    "        x3 = self.fc41(x)\n",
    "        x3 = self.relu(x3)\n",
    "        x3 = self.fc42(x3)\n",
    "        x3 = self.relu(x3)\n",
    "        x3 = self.dropout2(x3)\n",
    "        \n",
    "        x = x1 + x2 + x3\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b402a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, matthews_corrcoef, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def comp_result(y_test, y_pred, y_proba):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    \n",
    "    return accuracy,f1,auc,mcc,recall,precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6908d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "\n",
    "feature = np.array(feature)\n",
    "label = np.array(label)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kf_in = 0\n",
    "for train_index, test_index in kf.split(feature):\n",
    "    save_model = None\n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "    best_auc = 0\n",
    "    best_mcc = 0\n",
    "    best_recall = 0\n",
    "    best_precision = 0\n",
    "    print(train_index)\n",
    "    kf_in += 1\n",
    "    print('kf',kf_in)\n",
    "    X_train, X_test = list(feature[train_index]), list(feature[test_index])\n",
    "    y_train, y_test = list(label[train_index]), list(label[test_index])\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    cache_directory = \"\"\n",
    "\n",
    "\n",
    "    tokenizer_ = AutoTokenizer.from_pretrained(\"facebook/esm2_t30_150M_UR50D\", cache_dir=cache_directory)\n",
    "    esm2 = AutoModel.from_pretrained(\"facebook/esm2_t30_150M_UR50D\", cache_dir=cache_directory)\n",
    "    model = myModel(esm2)\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "    batch_size = 1 \n",
    "\n",
    "    data_loader = DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "    test_data_loader = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    num_epochs = 60\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        for batch_input, batch_labels in data_loader:\n",
    "\n",
    "            inputs = tokenizer_(batch_input, return_tensors='pt', padding=True, truncation=True)\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(-1)\n",
    "            loss = criterion(outputs.to('cpu'), batch_labels.to(torch.float32))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        model.eval()  \n",
    "        test_loss = 0\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        test_labels_com = []\n",
    "        predict_labels_com = []\n",
    "        test_outputs_com = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for test_batch_input, test_batch_labels in test_data_loader:\n",
    "                inputs = tokenizer_(test_batch_input, return_tensors='pt', padding=True, truncation=True)\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "\n",
    "                test_outputs = model(inputs)\n",
    "                test_outputs = test_outputs.view(-1)\n",
    "                test_loss += criterion(test_outputs.to('cpu'), test_batch_labels.to(torch.float32)).item()\n",
    "                predictions = (test_outputs > 0.5).float()  \n",
    "                correct_predictions += (predictions.to('cpu') == test_batch_labels).sum().item()\n",
    "\n",
    "    \n",
    "    \n",
    "                predict_labels_com.extend(predictions.tolist())\n",
    "                test_labels_com.extend(test_batch_labels.tolist())\n",
    "                test_outputs_com.extend(test_outputs.tolist())\n",
    "            \n",
    "            \n",
    "            \n",
    "        average_test_loss = test_loss / len(test_data_loader)\n",
    "        accuracy = correct_predictions / len(X_test)\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        predict_labels_com = np.array(predict_labels_com)\n",
    "        test_labels_com = np.array(test_labels_com)\n",
    "        test_outputs_com = np.array(test_outputs_com)\n",
    "        temp_accuracy,temp_f1,temp_auc,temp_mcc,temp_recall,temp_precision = comp_result(test_labels_com,predict_labels_com,test_outputs_com)\n",
    "        if temp_accuracy > best_accuracy:\n",
    "            best_accuracy = temp_accuracy\n",
    "            best_f1 = temp_f1\n",
    "            best_auc = temp_auc\n",
    "            best_mcc = temp_mcc\n",
    "            best_recall = temp_recall\n",
    "            best_precision = temp_precision\n",
    "            save_model = cp.deepcopy(model)\n",
    "            \n",
    "\n",
    "        average_train_loss = total_loss / len(data_loader)\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "            epoch + 1, num_epochs, average_train_loss, average_test_loss, accuracy * 100))\n",
    "        \n",
    "    print('=====================================')\n",
    "    print('kf',kf_in,\"best result:\")\n",
    "    print(best_accuracy)\n",
    "    print(best_f1)\n",
    "    print(best_auc)\n",
    "    print(best_mcc)\n",
    "    print(best_recall)\n",
    "    print(best_precision)\n",
    "    print('=====================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7633e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b91ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
